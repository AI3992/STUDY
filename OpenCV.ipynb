{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명시적인 규칙을 만드는 방법은 잘 동작하지도 않으며 알고리즘이 강하지도 못 하고 새로운 객체를 인식해야 할 때 그 객체에 대한 규칙을 하나하나 명시해야 한다는 단점이 존재하여 확장성이 없는 방법이다\n",
    "\n",
    "그렇기에 존재하는 다양한 객체들에게 유연하게 적용 가능한 확장성 있는 알고리즘을 만들어야 하는데 이런 일들을 간으하게 하는 인사이트가 데이터 중심 접근방법(Data-Driven Approcach)이다.\n",
    "\n",
    "객체마다 이 객체는 무엇이다 라고 하면서 직접 규칙을 써내는 것 대신에 인터넷에 접속하여 객체의 데이터를 수집하고 수집한 데이터들을 가지고 Machine Learning Classifier를 학습 시킬 수 있다\n",
    "\n",
    "머신러닝 알고리즘은 어떤 식으로든 데이터를 요약하여 다양한 객체들을 인식할 수 있는 모델을 만들어 낸다\n",
    "\n",
    "그리고 학습 모델로 새로운 이미지를 테스틀해 보면 객체들을 잘 인식할 것이다\n",
    "\n",
    "api를 변경하여 입력이미지를 객체로 인식하려면 함수가 두 개 필요하다\n",
    "\n",
    "하나는 Train함수이며 입력으로 이미지와 레이블을 받고, 출력으로 우리의 모델을 만들어 낸다.\n",
    "\n",
    "다른 하나는 Predict함수이며,  입력으로 모델을 받고, 출력은 이미지의 예측값을 반환한다.\n",
    "\n",
    "데이터 중심 접근방법은 딥러닝뿐만 아니라 아주 일반적인 개념이다.\n",
    "\n",
    "심플한 Classifier를 하나 보자면 Nearest neigher이 존재하는데, 해당 알고리즘은 매우 단순하다.\n",
    "Train Step에서는 아무 일도 하지 않고 그저 모든 학습 데이터를 기억하고\n",
    "Preidict Step에서는 새로운 이미지가 들어오면 해당 이미지와 기존의 학습 데이터를 비교하여 가장 유사한 이미지로 레이블링을 예측해낸다. \n",
    "\n",
    "매우 단순한 알고리즘이지만 Data-driven Approach로서는 아주 좋은 알고리즘이다.\n",
    "\n",
    "Cifar-10이라는 머신러닝에 자주 쓰이는 연습용 데이터가 존재하는데 해당 데이터를 이용할 것이다.\n",
    "\n",
    "CIFAR-10에는 10가지 클래스가 존재하며 총 50,000여개의 학습용 이미지가 존재한다.\n",
    "데이터들은 각 카테고리에 균일하게 분포하고 있다\n",
    "\n",
    "추가로 알고리즘 테스트용 10,000여개의 테스트 이미지가 있다\n",
    "테스트 데이터와 학습 데이터를 유사한 순으로 정렬을 하게 되면 눈으로 보기에는 비슷해 보이는 데이터들이 많이 보이지만 항상 그런 것만은 아닙니다.\n",
    "\n",
    "\n",
    "데이터들은 32 * 32 사이즈로 이루어져 있다.\n",
    "\n",
    "두 번째 행의 이미지는 개 이다. 거기에 가장 가까운 이미지도 개의 이미지이다.\n",
    "하지만 2,3등을 살펴보면 사슴이나 말로 보이는 이미지가 있는것을 볼 수 있다\n",
    "\n",
    "개는 아니지만 눈으로 보기에는 비슷해 보이는 이미지들이다 중간에 흰색 물체가 있는 등이 말이다.\n",
    "\n",
    "이 이미지에 NN 알고리즘을 적용하면 트레이닝 셋에서 가장 가까운 샘플을 찾게된다.\n",
    "\n",
    "추가로 두 번째 행의 테스트 이미지도 개 인데, NN 알고리즘이 잘 동작하지 않을 것 같아 보이지만\n",
    "해 볼만한 좋은 예제이다.\n",
    "\n",
    "중요한 점은 이미지 쌍이 있을 때 어떻게 비교할 것인지가 관건이다.\n",
    "\n",
    "테스트 이미지 하나를 모든 학습 이미지들과 비교할 때 여러 비교 방법들이 있는데\n",
    "정확이 말하면 어떤 \"함수\"를 사용할지에 달려있다.\n",
    "\n",
    "그 중 하나는 L1 Distance를 사용하는 것인데 Manhattan distance라고도 불린다.\n",
    "L1 Distance는 이미지를 Pixel-wise로 비교한다.\n",
    "만약 4*4 테스트 이미지가 있다고 생각을 하면\n",
    "테스트/트레이닝 이미지의 같은 자리의 픽셀을 서로 빼고 절댓값을 취한다\n",
    "이렇게 픽셀 간의 차이 값을 계산하고 모든 픽셀의 수행 결과를 모두 더한다\n",
    "Image Classification 문제에선 이 방법이 별로인 것 같지만 연습삼아 해보면 좋다\n",
    "\n",
    "\"두 이미지간의 차이를 어떻게 측정할 것인가?\" 에 구체적인 방법을 제시하면\n",
    "현재 예제의 경우 두 이미지간에 \"456\" 만큼 차이가 나는데\n",
    "\n",
    "NN Classifier를 구현한 Python 코드는 짧고 간결하다\n",
    "Numpy에서 제공하는 Vectorizaed operations을 이용하기 때문이다\n",
    "여기에서 앞서 말했던 Train 함수를 볼 수 있다.\n",
    "NN의 경우 Train함수가 단순하다.\n",
    "간지 학습 데이터를 기억하는 것이기 때문이다.\n",
    "\n",
    "Test 함수에서는 이미지를 입력으로 받고\n",
    "L1 Disrance로 비교하여 학습 데이터들 중 테스트 이미지와 가장 유사한 이미지들을 찾아낸다\n",
    "\n",
    "Numpy의 vectorized operations을 활용하면 구현은 Python code 한 두 줄이면 충분\n",
    "\n",
    "TrainSet의 이미지가 총 N개라면 Train/Test 함수의 속도는 어떻게 되는가?\n",
    "1. Train time은 상수 시간0(1)이다. 데이터를 기억하기만 하면 되기 때문이다.\n",
    "1. Test time은 N개의 학습 데이터 전부를 테스트 이미지와 비교해야만 하기에 굉장히 느린 작업이 된다.\n",
    "1. 실제로 Train Time은 느려도 상관이 없지만 Test Time에서는 작업이 빨리 끝나기를 바란다.\n",
    "1. 만약 내가 데이터 센터에서 어떤 Classifier를 학습시키고 있다고 생각하면\n",
    "1. 좋은 성능을 보장하기 위해서 Train Time에 많은 시간을 쏟을 수도 있지만\n",
    "1. Classifier의 Test Time을 생각해보면 이 모델이 모바일이나 브라우저등 Low Power Device에서 동작해야 할 수도 있다.\n",
    "1. 이런 상활에서는 Classifier가 Test Time에서 어느정도 빠른 성능을 보장해야 할 것이다.\n",
    "1. 그런 관점에서 CNN 알고리즘은 정 반대의 경우이다.\n",
    "1. CNN 같은 parametic model들은 NN과는 정 반대이다.\n",
    "1. Train Time이 굉장히 오래 걸릴지 모르나 Test Time은 굉장히 빠르다\n",
    "\n",
    "NN 알고리즘을 적용 시켰을 때\n",
    "NN의 decision regions을 그려보자\n",
    "\n",
    "## cs231n 00:19:30\n",
    "\n",
    "2차원 평면 상의 여러 점들이 보이는데 이 점들은 학습 데이터이다.\n",
    "점의 색은 클래스 레이블(카테고리)이다\n",
    "해당 예제에서는 색이 5개로 클래스가 5개 라는 것을 알 수 있다.\n",
    "2차원 평면 내의 모든 좌표에서 각 좌표가 어떤 학습 데이터와 가장 가까운지 계산을 한다\n",
    "그리고 각 좌표를 해당 클래스의 해당하는 색을 칠해준다\n",
    "NN 분류기 같은 경우엔 공간을 나눠서 각 레이블을 분류한다.\n",
    "하지만 이 분류기는 문제가 있다\n",
    "예제를 보면 NN 분류기에서 발생 가능한 문제들을 살펴볼 수 있다.\n",
    "가운데 부분을 보면 주변은 초록색인 반면, 정가운데만 노란색인 것을 확인할 수 있는데 이는 NN 알고리즘이 가장 가까운 이웃만을 보기 때문에, 녹색 무리 한 가운데 노란색 영역이 생겨버린 것이다.\n",
    "원래라면 노란색이 아닌 초록색 영역이여야 한다\n",
    "이것과 비슷하게 초록색 영역이 파란색 영역을 침범하는 것을 확인할 수 있는데 이 점(학습한 데이터)은 잡음(noise)이거나 가짜(spurious)일것이다.\n",
    "\n",
    "이러한 문제들이 발생하기 때문에 NN에서 조금 더 일반화된 버전인 K-NN 알고리즘이 탄생하게되었다.\n",
    "Disrance metric을 이용해서 가까운 이웃을 K개 만큼 찾고, 이웃끼리 투표를 하는 방법이다\n",
    "\n",
    "그리고 가장 많은 득표수를 획득한 레이블로 예측을 하는 것이다\n",
    "투표를 하는 과정이 다양하고 복잡한 방법들이 있을 수 있다 거리별 가중치를 고려하기 같은 것이 있다\n",
    "하지만 가장 잘 작동하면서도 가장 쉬운 방법은 득표수만 고려하는 방법이다\n",
    "\n",
    "## cs231n 00:21:29\n",
    "\n",
    "보이는 세 예제는 동일한 데이터를 사용한 k-nn 분류기들이다\n",
    "각각 kk=1/3/5 에서의 결과들이다\n",
    "\n",
    "k=3의 경우 앞서 초록색 영역에 자리 잡았던 노란색 점 때문에 생긴 노란 지역이 사라졌습니다.\n",
    "좌측에 있던 파란색 영역을 침범하던 부분도 부드러워지고 있습니다.\n",
    "\n",
    "k=5의 경우 빨간 영역과 파란 영역의 경계가 완전이 부드러워진것을 볼 수 있습니다.\n",
    "대게 NN분류기를 사용하면 , K는 적어도 1보다는 큰 값을 사용합니다.\n",
    "왜냐하면 K가 1보다 커야 결정 경계가 더 부드러워지고 더 좋은 결과를 보이기 때문입니다.\n",
    "\n",
    "## 질문 - 레이블링이 안된 흰색 지역은 어떻게 처리하는지?\n",
    "\n",
    "흰색 영역은 k-nn이 \"대다수\"를 경정할 수 없는 지역입니다.\n",
    "흰색 영역을 매꿀 수 있는 더 좋은 방법들도 있습니다.\n",
    "\n",
    "어떤 식으로든 추론을 해보거나, 임의로 정하는게 가능하다\n",
    "하지만 이번에는 단순한 예제라서 가장 가까운 이웃이 존재하진 않으면 단순하게 흰색으로 칠했습니다.\n",
    "\n",
    "computer vision을 공부하는 동안에 다양한 관점을 유연하게 다루는 능력은 매우 유용하다\n",
    "그 중 하나는 바로 이미지를 고차원 공간에 존재하는 하나의 점이라고 생각하는 것인데, 반대로 이미지를 이미지 자체로 볼 수도 있다는 것이죠\n",
    "\n",
    "이미지의 픽셀들을 하나의 고차원 벡터로 생각하는 관점이다.\n",
    "이 두 괌점을 자유롭게 오갈 수 있는 능력은 아주 유용합니다.\n",
    "\n",
    "이미지를 다루는 문제에는 k-nn을 사용하는 전략은 그리 좋지 않은 방법입니다.\n",
    "\n",
    "## cs231n 00:23:29\n",
    "\n",
    "잘 분류되었는지 아닌지를 빨강/초록으로 표기했습니다.\n",
    "성능이 그리 좋지 않습니다.\n",
    "\n",
    "그럼 K값을 올리면 어떻게 되는가? 가장 가까운 이웃 뿐만 아니라\n",
    "Top-3/Top-5 혹은 모든 행(Row)을 사용하면 어떨까?\n",
    "결과는 더 많은 이웃들이 투표에 참여하여 각종 잡음들에 조금 더 강인해 질 것으로 추측할 수 있다\n",
    "\n",
    "k-nn을 사용할 때 결정해야 할 사항이 한 가지 더 있는데\n",
    "바로 서로 다른 점들을 어떻게 비교할 것인지 이다.\n",
    "\n",
    "지금까지는 L1 Dustance을 이용하였는데\n",
    "이는 픽셀 간 차이 절대값의 합 이다\n",
    "\n",
    "하지만 L2, 즉 Euclidean distance를 사용해도 된다\n",
    "제곱 합의 제곱근을 거리로 이용하는 방법이다\n",
    "\n",
    "어떤 거리 척도(distance metric)을 선택할지는 아주 흥미로운 주제이다\n",
    "왜냐하면 서로 다른 척도에서는 해당 공간의 근본적인 기하학적 구조 자체가 서로 다르기 때문이다.\n",
    "\n",
    "## cs231n 00:24:35\n",
    "\n",
    "왼쪽에 보이는 사각형은 L1 Distance의 관점에서는 원이다.\n",
    "생긴 모습은 우너점을 기준으로 하는 사각형의 모양이지만\n",
    "L1의 관점에서는 사각형 위의 점들이 모두 원점으로부터 동일한 거리만큼 떨어져 있다.\n",
    "\n",
    "반면, L2, Euclidean distance의 관점에서는 원이다\n",
    "일반적으로 생각하는 원 모양이다\n",
    "\n",
    "이 두 가지 거리 척도간에는 아주 흥미로운 차이점이 있는데\n",
    "L1은 어떤 좌표 시스템이냐에 따라 많은 영향을 받는다.\n",
    "가령 기존의 좌표계를 회전시키면\n",
    "L1 distance가 변하는 반면 L2 Distance의 경우에는 좌표계와 아무 연관이 없다.\n",
    "\n",
    "\n",
    "만약 특징 벡터의 각각 요소들이 개별적인 의미를 가지고 있다면\n",
    "L1 Distance가 더 잘 어울릴 수도 있다\n",
    "\n",
    "하지만 특징 벡터가 일반적인 벡터이고, 요소들간의 실질적인 의미를 잘 모르는 경우하면,\n",
    "아마 L2 Distancer가 더 잘 어울릴 수도 있다\n",
    "\n",
    "여기서 주목할 점은 k-nn에 다양한 거리 척도를 적용하면\n",
    "k-nn으로 다양한 종류의 데이터를 다룰 수 있다는 점이다.\n",
    "벡터나 이미지 외에도 말이다.\n",
    "가령 문장을 분류하는 문제가 있다고 하면\n",
    "k-nn 분류기로 이 문제를 다루려면\n",
    "어떤 거리 척도를 사용할지만 정해주면 된다.\n",
    "두 문장 간의 거리를 츨정할 수 있는 어떤 것이든 사용하면 된다.\n",
    "거리 척도만 정해주면 어떤 종류의 데이터도 다룰 수 있다.\n",
    "\n",
    "k-nn은 아주 단순한 알고리즘이다, 하지만 새로운 문제를 접했을 때,\n",
    "간단히 시도해 볼만한 아주 좋은 알고리즘이다.\n",
    "\n",
    "그러면 어떤 거리 척도를 사용하는지에 따라서 실제 기하학적으로 어떻게 변하는지 알아보자\n",
    "\n",
    "## cs231n 00:26:28\n",
    "\n",
    "양 쪽 모두 동일한 데이터이다. 다만 왼쪽은 L1 Distance를 오른쪽은 L2 Distance를 사용하였다.\n",
    "결과를 보면 거리 척도에 따라서 결정 경계의 모양 자체가 달라진다는 것을 알 수 있다\n",
    "L1 Distance를 살펴보면 경정 경계가 \"좌표 축\"에 영향을 받는 경향을 알 수 있다.\n",
    "L1 Dustance가 좌표 시스템의 영향을 받기 때문이다.\n",
    "\n",
    "반면 L2 Distance 는 좌표 축의 영향을 받지 않고 결정 경계를 만들기 때문에 더 자연스럽다\n",
    "\n",
    "자신이 k-nn을 사용하려고 한다면, 반드시 선택해야 하는 몇 가지 항목이 있는데\n",
    "\n",
    "앞서 K에 대해서 이야기하였고, L1, L2와 같은 거리 척도 또한 다루었다\n",
    "\n",
    "그렇다면 어떻게 하면 \"네 문체\"와 \"데이터\"애 꼭 맞는 모델을 찾을 수 있을까?\n",
    "K와 거리척도를 하이퍼 파라미터 라고 하는데\n",
    "하이퍼파라미터는 Train time에 학습하는 것이 아니므로\n",
    "학습 전 반드시 선택해야만 한다.\n",
    "\n",
    "데이터로 직접 학습시킬 방법이 없다.\n",
    "\n",
    "그렇다면 하이퍼파라미터를 어떻게 정해야 할까?\n",
    "\n",
    "하이퍼파라미터를 정하는 일은\n",
    "문제의존적(problem-dependent)이다\n",
    "\n",
    "가장 간단한 방법은 데이터에 맞게 다양한 하이퍼파라미터 값을 시도해 보고 가장 좋은 값을 찾는 것이다\n",
    "\n",
    "## 질문 - 어떤 경우에 L1 Distance가 L2 Distance보다 더 좋은지?\n",
    "\n",
    "이것은 문제의존적(problem-dependent)이다\n",
    "\n",
    "어떤 경우에 L1/L2를 써야 하느지 결정하는 것은 어렵겠지만\n",
    "L1은 좌표계에 의존적이므로 데이터가 좌표계에 의존적인지를 판단하는 것이 판단 기준이 될 수 있다.\n",
    "\n",
    "본인에세 어떤 특징 벡터가 있고 각 요소가 어떤 특별한 의미를 지니고 있다면\n",
    "가령 직원들을 분류하는 문제가 있을 때, 데이터의 각 요소가 직원들의 다양한 특징에 영향을 줄 수 있다.\n",
    "가령 봉급, 근속년수와 같은 예가 될 수 있다.\n",
    "\n",
    "이처럼 각 요소가 특별한 의미흫 가지고 있다면 L1을 사용하는 것이 좀 더 괜찮을 지도 모른다.\n",
    "하지만 일반적으로는 하이퍼파라미터 선택은 어떤 문제와 데이터인지에 의존적이다.\n",
    "\n",
    "하이퍼파라미터는 단지 여러가지 시도를 해보고 좋은 것을 선택하는 것이 좋다.\n",
    "\n",
    "하지만 하이퍼파라미터 값들을 실험해 보는 작업도 다양하다\n",
    "\n",
    "다양한 하이퍼 파라미터를 시도해 보는 것과 그중 최고를 선택하는 것이 무슨 뜻일까?\n",
    "\n",
    "가장 먼저 떠올릴 수 있는 아이디어는 아주 단순하다\n",
    "\n",
    "학습데이터의 정확도와 선능을 최대화하는 하이퍼파라미터를 선택하는 것이다\n",
    "\n",
    "사실 정말 끔찍한 방법이다.\n",
    "절대로 이렇게 해서는 안됩니다.\n",
    "\n",
    "가령 NN분류기의 경우 K = 1 일 때\n",
    "학습 데이터를 가장 완벽하게 분류한다.\n",
    "\n",
    "앞서 말씀드린 전략대로라면 항상 K = 1 일 때가 최고가 된다.\n",
    "\n",
    "하지만 앞선 예제에서도 보았듯이, 실제로는 K를 더 큰 값으로 선택하는 것이 학습 데이터에서는 몇 개 잘못 분류할 수 있지만 학습 데이터에 없던 데이터에 대해서는 더 좋은 선능을 보일 수 있다\n",
    "\n",
    "궁극적으로 기계학습에서는 학습 데이터를 얼마나 잘 맞추는지는 중요하지 않다\n",
    "\n",
    "학습시킨 분류기가 한번도 보지 못한 데이터를 얼마나 잘 예측하는지가 중요하다\n",
    "\n",
    "그러므로 학습 데이터에만 신경쓰는 것은 최악이며 추천하지 않는다\n",
    "\n",
    "또 다른 아이디어는 전체 데이터셋 중 학습 데이터를 쪼개서 일부를 테스트 데이터로 사용하는 것입니다.\n",
    "\n",
    "학습 데이터로 다양한 하이퍼파라미터 값들을 학습 시키고 테스트 데이터에 적용시켜본 다음, 하이퍼파라미터를 선택하는 방법이다\n",
    "이 방법은 조금 더 합리적인 것 같지만 사실은, 이 방법 또한 아주 끔찍한 방법으로 하면 안된다.\n",
    "\n",
    "다시 한번 기계학습의 궁극적인 목적을 말씀드리자면 한번도 보지 못한 데이터에서 잘 동작해야 한다\n",
    "테스트셋으로는 한번도 보지 못했던 데이터에서의 알고리즘의 성능을 측정할 수 있어야 합니다.\n",
    "\n",
    "그런데 만약 학습시킨 모델들 중 테스트 데이터에 가장 잘 맞는 모델을 선택한다면\n",
    "우리는 그저 \"데스트셋에서만\" 잘 동작하는 하이퍼파라미터를 고른 것일 수 있다.\n",
    "\n",
    "그렇게 되면, 더 이상 테스트 셋에서의 성능은 한번도 보지 못한 데이터에서의 성능을 대표할 수는 없다.\n",
    "\n",
    "그러니 이 또한 하지 말아야하는 생각이다. 이렇게 한다면 곤경에 빠질 것이다\n",
    "\n",
    "훨씬 더 일반적인 방법은 데이터를 세 개로 나누는 것입니다.\n",
    "\n",
    "데이터의 대부분은 트레이닝 셋으로 나누고, 일부는 밸리데이션 셋, 그리고 나머지는 테스트 셋으로 나눈다.\n",
    "\n",
    "그리고 다양한 하이퍼파라미터로 \"트레이닝 셋\"을 학습시킨다\n",
    "\n",
    "그리고 \"벨리데이션 셋\"으로 검증을 한다. 그 후 벨리데이션 셋에서 가장 좋았던 하이퍼파라미터를 선택한다\n",
    "\n",
    "최종적으로 개발/디버깅 등 모든 일들을 다 마친 후에\n",
    "벨리데이션 셋에서 가장 좋았던 분류기를 가지고 테스트 셋에서는 \"오로지 한번만\" 수행하고\n",
    "나온 수치가 알고리즘이 한번도 보지 못한 데이터에 얼마나 잘 동작해 주는지 실질적으로 알려주는 것이다.\n",
    "\n",
    "실제로 벨리데이션 데이터와 테스트 데이터를 엄격하게 나눠놓는 것은 중요하다\n",
    "\n",
    "또 다른 하이퍼파라미터 선택 전략은 크로스 벨리데이션(교차 검증) 이다\n",
    "이 방법은 작은 데이터셋일 경우 많이 사용하고 딥러닝에서는 많이 사용되지 않는다\n",
    "\n",
    "이 아이디어는 테스트 데이터를 정해놓고, 정한 테스트 데이터는 제일 마지막에만 사용할 것이다\n",
    "\n",
    "그리고 나머지 데이터는 트레이닝/벨리데이션 으로 나눠 놓는 대신에 트레이닝 데이터를 여러부분으로 나눠준다.\n",
    "\n",
    "이런 식으로 번갈아가면서 벨리데이션 셋을 지정해 준다.\n",
    "\n",
    "## cs231n 00:34:41,498\n",
    "\n",
    "이 예제에서는 5-Fold Cross Validation을 사용하고 있다\n",
    "\n",
    "처음 4개의 fold에서 하이퍼 파라미터를 학습시키고 남은 한 fold에서 알고리즘을 평가한다\n",
    "\n",
    "그리고 1, 2, 3, 5 fold에서 다시 학습시키고 4 fold로 평가한다.\n",
    "\n",
    "## cs231n 영상 참고\n",
    "\n",
    "이런식으로 계속 순환된다.\n",
    "\n",
    "이런 방식으로 최적의 하이퍼파라미터를 확인할 수 있을 것이다\n",
    "\n",
    "이런 방식은 거의 표준이긴 하지만 시제로는 딥러닝같은 큰 모델을 학습시킬 때는 학습 자페가 계산량이 많기 때문에 실제로는 잘 쓰지 않는다\n",
    "\n",
    "## 질문 - 구체적으로 트레이닝 셋과 벨릭데이션 셋의 차이가 무엇인가\n",
    "\n",
    "K-NN의 예를 들어보자면 트레이닝셋은 우리가 레이블을 기억하고 있는 이미지들 이다\n",
    "어떤 이미지를 부류하여면 트레이닝 데이터의 모든 이미지들과 비교하게 된다.\n",
    "\n",
    "그리고 가장 근접한 레이블을 선택하고 알고리즘은 트레이닝 셋 자체를 기억할 것이다\n",
    "이제는 벨리데이션 셋을 가져와 트레이닝 셋과 비교한다\n",
    "그리고 이를 통해서 벨릳데이션 셋에서는 분류기가 얼마만큼의 정확도가 나오는지 확인한다.\n",
    "\n",
    "이것이 트레이닝/벨리데이션 셋의 차이점이다\n",
    "트레이닝 셋의 레이블을 볼 수 있지만 벨리데이션 셋의 레이블은 볼 수 없다\n",
    "벨리데이션 셋의 레이블은 알고라짐이 얼마나 잘 동작하는지를 확인할 때만 사용한다\n",
    "\n",
    "## 질문 - 테스트 셋이 한번도 보지 못한 데이터를 대표할 수 있는가\n",
    "\n",
    "실제로 문제가 될 수 있음\n",
    "\n",
    "기본적인 통계학적 가정이 하나 있는데 데이터는 독립적이며, 유일한 하나의 분포애서 나온다는 가정이다\n",
    "그러니 모든 데이터는 동일한 분포를 따른다고 생각해야 한다.\n",
    "물론 실제로는 그렇지 않은 경우가 대다수다\n",
    "테스트 셋이 한번도 보지 못한 데이터를 잘 표현하지 못 하는 경우를 경험하게 될 것이다\n",
    "그리고 이런 유희 문제는 datasets crators와 dataset curators가 생각해 볼 문제이다\n",
    "\n",
    "하지만 가령 내가 데이터 셋을 만들때 하는 한가지 일은\n",
    "데이터를 수집할 때. 일관된 방법론을 가지고 대량의 데이터를 한번에 수집하는 전략을 사용한다.\n",
    "\n",
    "그다음에 무작위로 트레이닝 데이터와 테스트 데이털를 나눠준다\n",
    "\n",
    "한가지 주의할 점은 데이터를 지속적으로 모으고 있는 경우이다\n",
    "\n",
    "먼저 수집한 데이터들을 트레이닝 데이터로 쓰고 이후에 모은 데이터를 테스트 데이터로 사용한단면 문제가 될 수 있습니다.\n",
    "\n",
    "대신에 데이터셋 전체를 무작위로 섞어서 데이터셋을 나누는 것이 그 문제를 완화 시킬 수 있는 한가지 방법일 수 있습니다\n",
    "\n",
    "크로스 벨리데이션 을 수행하고 나면 다음과 같은 그래프를 보실 수 있습니ㅏㄷ.\n",
    "X축은 K-NN의 K이다. 그리고 Y축은 분류 정확도이다.\n",
    "\n",
    "## cs231n 영상 참고 cs231n 00:38:26\n",
    "\n",
    "이 경우에는 5-fold 크로스 벨리데이션을 수행하였다.\n",
    "각 K마다 5번의 크로스 벨리데이션을 통해 알고리즘이 얼마나 잘 동작하는지를 알려준다\n",
    "\n",
    "그리고 \"테스트셋이 알고리즘 성능 향상에 미치는 영향\"을 알아보려면 k dold크로스벨리데이션이 도움을 줄 수 있습니다.\n",
    "여러 calidation folds 별 성능의 분산(variance)을 고려해 볼 수 있다.\n",
    "분산을 같이 계산하게 되면, 어떤 하이퍼파라미터가 가장 좋은지 뿐만 아니라, 그 성능의 분산도 알 수 있다\n",
    "\n",
    "## cs231n 영상 참고 cs231n 00:39:04\n",
    "\n",
    "기계학습 모델을 학습시키는 경우에 보통 이런 모습의 드래프를 그리게 될 것이다\n",
    "하이퍼파라미터에 따라 모델의 정확도와 선능을 평가할 수 있다\n",
    "그리고 벨리데이션 셋의 성능이 최대인 하이퍼파라미터를 선택하게 될 것이다.\n",
    "이 예제에서는 아마도 K = 7일 경우에 가장 좋은 성능을 내는 것을 알 수 있다\n",
    "아마도 실제로는 입력이 이미지인 경우에도 K-NN 분류기를 잘 사용하지 않는다\n",
    "앞서 서술한 문제들 때문이다\n",
    "\n",
    "우선 한 가지 문제점은 k-nn이 너무 느리다는 것이다.\n",
    "우리가 원하는 것과 정 반대이며 이 내용은 앞서 이야기한 적이 있었습니다.\n",
    "하나의 문제는 L1/L2 Distance가 이미지간의 거리를 측정하기에 적절하지 않다는 점이다.\n",
    "이벡터간의 걸 츨정 관련 함수들은 이미지들 강의 \"지각성 유사성\"을 측정하는 척도로는 적절하지 않다\n",
    "\n",
    "## cs231n 영상 참고 cs231n 00:40:01\n",
    "\n",
    "우리들은 이미지간의 차이를 어떻게 자각하는 것일까\n",
    "만약 이곳 왼쪽에 한 여성이 있다고 치면\n",
    "오른쪽에는 세개의 왜곡된 이미지가 있다\n",
    "눈과 입을 가려도 보고, 몇 픽실씩 이동도 시켜보고 전체 이미지에 파란색 색조도 추가시켜 보았습니다\n",
    "그리고 각 이미지와 원본의 사이의 Euclidean Distance를 측정해보면 이들은 모두 동일한 L2 Distance를 가진다.\n",
    "\n",
    "좋지 않은 현상이다\n",
    "\n",
    "이는 L2 Distance가 이미지들 간의 \"자각적 유사도\"를 측정하기에는 적합하지 않다는 의미이기 때문이다\n",
    "\n",
    "K-NN의 또 다른 문제 중 하나는 바로 \"차원의 저주\"이다\n",
    "\n",
    "K-NN을 다시한번 살펴보면 K-NN가 하는 일은 트레이닝 데이터를 이용해서 공각을 분할하는 일이였습니다.\n",
    "\n",
    "이는 K-NN이 잘 동작하려면 전체 공간을 조밀하게 커버할 만큼의 충분한 트레이닝 샘플이 필요하다는 것을 의미합니다.\n",
    "\n",
    "그렇지 않다면 이웃이 사실은 어청 멀 수도 있고 그렇게 되면 테스트 이미지를 제대로 분류할 수 없을 것입니다.\n",
    "공간을 조밀학게 덮으려면 충분한 량의 학습 데이터가 필요하고 그 양은 차원이 증가함에 따라 기하급수적으로 증가한다\n",
    "아주 좋지 않은 현상이다\n",
    "기하급수적인 증가는 언제나 옳지 못하다\n",
    "\n",
    "고차원의 이미지라면 모든 공간을 조밀하게 메울 만큼의 데이터를 모으는 일은 현실적으로 불가능하다\n",
    "K-NN을 사용할 시 이 점을 항상 염두해야 한다\n",
    "\n",
    "요약을 해보자면 이미지 분류가 무엇인지 설명하기 위해 K-NN 예제를 들어보았다\n",
    "\n",
    "\"이미지\"와 \"정답 레이블\"이 있는 트레이닝 셋이 있었고 테스트 셋을 예측하는데 이용하였다\n",
    "\n",
    "## 질문 - cs231n 영상의 00:41:13 슬라이드의 그림이 무엇을 의미하는지\n",
    "## 그림의 초록 점과 파란 점은 무엇인가?\n",
    "\n",
    "각 점은 트레이닝 샘플들을 의미한다.\n",
    "점 하나하나가 트레이닝 샘플이다\n",
    "그리고 각 점의 색은 트레이닝 샘플이 속한 카테고리를 나타낸다고 보면 된다\n",
    "가령 맨 왼쪽의 1차원을 보면 이 공간을 조밀하게 덮으려면 트레이닝 샘플 4개면 충분하다\n",
    "2차원 공간을 다 덮으려면 16개가 필요한데 이는 1차원의 4배이다\n",
    "이렇게 3, 4, 5 차원 같이 고차원을 고려해보면 각 공간으 조밀하게 덮기 위해 필요한 트레이닝 샘플의 수는 차원이 늘어남에 따라 기하급수접으로 증가한다.\n",
    "그리고 가령 2차원 공간에서는  커브모양이 있다\n",
    "혹은 더 높은 차원에선는 열종의 샘플들의 manifolds가 있을 수 있습니다.\n",
    "하지만 K-NN 알고리즘은 샘들들의 manidfold르 가정하지 않기 때문이다\n",
    "k-nn이 제대로 동작할 수 있는 유일한 방법은 공간을 조밀하게 덮을 만큼 춘불히 많은 트레이닝 샘풀을 가지는 것이다\n",
    "\n",
    "## 질문 - cs231n 영상의 00:43:34 왜 저 이미지들의 L2 Distance가 같은지? \n",
    "\n",
    "해당 이미지들이 같은 L2 Distance를 가지도롣 임의로 만들어냈기 때문이다\n",
    "단지 L2 Distance가 이미지간의 유사도를 측정하는데는 좋지 않다는 점을 강조하고 싶었다\n",
    "하지만 K-nn을 사용한다면 이미지 간의 유사도를 특정할 수 있는 유일한 방법은 \n",
    "이 단일 거리 선능 척도(L1 / L2 등)을 이용하는 수 밖에 없다\n",
    "이 예시는 Distance metric이 실제로는 이미지간의 유사도를 잘 포착해 내지 못한다는 것을 알려준다\n",
    "이 예시에 경우에 이러한 translarion과 offset에도 Distance가 일치하도록 제가 임의로 만들어낸 것이다.\n",
    "\n",
    "## 질문 - 이미지가 모두 같은 사람이므로 distance가 같으면 졿은거 아닌가?\n",
    "\n",
    "이 예시에서는 그럴 수 있다 그러나 반례가 있을 수 있다\n",
    "가령 서로 다른 두 개의 원본 이미지가 있고어떤 적절한 위치에 박스를 놓거나, 색을 더하거나 하게 되면 결국 두 이미지의 Distance를 엄청 가깝게 만들 수 있을 것이다.\n",
    "반대로 이 예시에서 똑같은 하나의 이미지에 \n",
    "이므이로 움직이거나(shift) 색을 더하면(tinting) Distance는 제먹대로 변할 것이다\n",
    "\n",
    "그러니 다양한 서로다른 이미지들이 같은 Distance를 가지는 경우라면 잘 못될 수도 있는 것입니다.\n",
    "\n",
    "## 질문 - 최적의 하이퍼파라미터를 찾을 때 까지 학습을 다시 시키는 것이 흔한 방법인지?\n",
    "\n",
    "실제로 사람들은 가끔 그러곤 한다\n",
    "하지만 그때 그때 다르다고 할 수 있다\n",
    "만약 데드라인에 쩣기고 있고 당장 사용해야 한다면\n",
    "데이터 셋 저부를 다시 학습시키는 것이 너무 오래 걸리면 다시 학습시키기 쉽지 않을 것이다.\n",
    "하지만 다시 학습시킬 여유가 있고 1%의 성능이라도 짜내고 싶다면 하나의 트릭이 될 수 있다\n",
    "지그까지 K-NN이 기계학습 알고리즘이라는 점에서 지닌 특성들에 대해 배웠다\n",
    "\n",
    "하지만 실제로는 성능이 엄청 좋지는 않다\n",
    "특히 이미지에는 잘 사용하지 않는다\n",
    "\n",
    "다음은 Linear Classification이다.\n",
    "Linear Classification은 아주 간단한 알고리즘이다. 하지만 아주 중요하고 NN과 CNN의 기반이 되는 알고리즘이다.\n",
    "일부 사람들은 Nerural Network을 레고블럭에 비유한다\n",
    "NN을 구축할 때 다양한 컴포넌트들을 사용할 수 있다\n",
    "이 컴퓨넌트들을 한데 모아서 CNN이라는 거대한 타워를 지울 수 있는 것이다\n",
    "앞으로 보게될 다양한 \n",
    "\n",
    "hi hello"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e309aa03de6348255f34ec61e6c540557e94286e07de902f5f868f03120cbf82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
